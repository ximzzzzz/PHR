{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_.csv')\n",
    "# data_x = data_x.iloc[:, data_x.columns!= 'DE1_dg' ]\n",
    "# data_y = data_x.iloc[:,data_x.columns=='DE1_dg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xx.to_csv('data_x.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nb-0242\\anaconda3\\envs\\ximz\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "c:\\users\\nb-0242\\anaconda3\\envs\\ximz\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    48660\n",
       "1.0     4021\n",
       "Name: DE1_dg, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y.loc[data_y['DE1_dg']==8.0,:] = 0\n",
    "data_y['DE1_dg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y.to_csv('data_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = StandardScaler().fit(data.iloc[:,data.columns!='DE1_dg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HE_wt</th>\n",
       "      <th>N_VITC</th>\n",
       "      <th>age</th>\n",
       "      <th>HE_BMI</th>\n",
       "      <th>HE_wc</th>\n",
       "      <th>N_FE</th>\n",
       "      <th>N_B1</th>\n",
       "      <th>N_B2</th>\n",
       "      <th>N_CA</th>\n",
       "      <th>N_CAROT</th>\n",
       "      <th>...</th>\n",
       "      <th>HE_BUN</th>\n",
       "      <th>HE_TG</th>\n",
       "      <th>HE_chol</th>\n",
       "      <th>BM8</th>\n",
       "      <th>BM7</th>\n",
       "      <th>BE3_31</th>\n",
       "      <th>L_OUT_FQ</th>\n",
       "      <th>HE_HBsAg</th>\n",
       "      <th>BD1_11</th>\n",
       "      <th>DE1_dg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.5</td>\n",
       "      <td>28.144062</td>\n",
       "      <td>38.0</td>\n",
       "      <td>22.070312</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9.906326</td>\n",
       "      <td>2.129463</td>\n",
       "      <td>1.162732</td>\n",
       "      <td>354.696362</td>\n",
       "      <td>2123.850327</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.7</td>\n",
       "      <td>14.517030</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.401699</td>\n",
       "      <td>75.0</td>\n",
       "      <td>14.080673</td>\n",
       "      <td>0.560153</td>\n",
       "      <td>0.483796</td>\n",
       "      <td>640.070701</td>\n",
       "      <td>286.469587</td>\n",
       "      <td>...</td>\n",
       "      <td>13.3</td>\n",
       "      <td>94.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.0</td>\n",
       "      <td>138.550033</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.494781</td>\n",
       "      <td>74.5</td>\n",
       "      <td>21.453717</td>\n",
       "      <td>2.670493</td>\n",
       "      <td>2.015267</td>\n",
       "      <td>595.618808</td>\n",
       "      <td>8277.230522</td>\n",
       "      <td>...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>215.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.9</td>\n",
       "      <td>103.136254</td>\n",
       "      <td>37.0</td>\n",
       "      <td>20.337484</td>\n",
       "      <td>72.4</td>\n",
       "      <td>54.075376</td>\n",
       "      <td>1.028786</td>\n",
       "      <td>0.601815</td>\n",
       "      <td>451.542912</td>\n",
       "      <td>4011.061803</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7</td>\n",
       "      <td>49.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.0</td>\n",
       "      <td>160.457330</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.792804</td>\n",
       "      <td>100.7</td>\n",
       "      <td>8.966009</td>\n",
       "      <td>0.722666</td>\n",
       "      <td>0.682925</td>\n",
       "      <td>312.266760</td>\n",
       "      <td>10330.283306</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8</td>\n",
       "      <td>96.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.1</td>\n",
       "      <td>0.560718</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.675532</td>\n",
       "      <td>96.6</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>0.108687</td>\n",
       "      <td>0.043766</td>\n",
       "      <td>19.642663</td>\n",
       "      <td>17.056209</td>\n",
       "      <td>...</td>\n",
       "      <td>26.9</td>\n",
       "      <td>102.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.7</td>\n",
       "      <td>99.117880</td>\n",
       "      <td>41.0</td>\n",
       "      <td>27.496295</td>\n",
       "      <td>83.0</td>\n",
       "      <td>16.572288</td>\n",
       "      <td>1.004673</td>\n",
       "      <td>1.137287</td>\n",
       "      <td>331.439696</td>\n",
       "      <td>5227.723890</td>\n",
       "      <td>...</td>\n",
       "      <td>17.9</td>\n",
       "      <td>74.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.7</td>\n",
       "      <td>39.229149</td>\n",
       "      <td>54.0</td>\n",
       "      <td>21.573651</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6.366494</td>\n",
       "      <td>0.821524</td>\n",
       "      <td>0.397352</td>\n",
       "      <td>239.383662</td>\n",
       "      <td>335.698035</td>\n",
       "      <td>...</td>\n",
       "      <td>12.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68.3</td>\n",
       "      <td>60.960609</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.117672</td>\n",
       "      <td>84.3</td>\n",
       "      <td>5.660753</td>\n",
       "      <td>0.558477</td>\n",
       "      <td>0.597908</td>\n",
       "      <td>409.751881</td>\n",
       "      <td>788.574381</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57.6</td>\n",
       "      <td>149.761943</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.806035</td>\n",
       "      <td>90.2</td>\n",
       "      <td>16.816691</td>\n",
       "      <td>2.687990</td>\n",
       "      <td>2.051522</td>\n",
       "      <td>671.774181</td>\n",
       "      <td>12941.982092</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3</td>\n",
       "      <td>162.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HE_wt      N_VITC   age     HE_BMI  HE_wc       N_FE      N_B1      N_B2  \\\n",
       "0   56.5   28.144062  38.0  22.070312   78.0   9.906326  2.129463  1.162732   \n",
       "1   63.7   14.517030  20.0  20.401699   75.0  14.080673  0.560153  0.483796   \n",
       "2   63.0  138.550033  23.0  21.494781   74.5  21.453717  2.670493  2.015267   \n",
       "3   54.9  103.136254  37.0  20.337484   72.4  54.075376  1.028786  0.601815   \n",
       "4   91.0  160.457330  30.0  33.792804  100.7   8.966009  0.722666  0.682925   \n",
       "5   60.1    0.560718  70.0  26.675532   96.6   0.998063  0.108687  0.043766   \n",
       "6   56.7   99.117880  41.0  27.496295   83.0  16.572288  1.004673  1.137287   \n",
       "7   50.7   39.229149  54.0  21.573651   76.0   6.366494  0.821524  0.397352   \n",
       "8   68.3   60.960609  21.0  25.117672   84.3   5.660753  0.558477  0.597908   \n",
       "9   57.6  149.761943  64.0  25.806035   90.2  16.816691  2.687990  2.051522   \n",
       "\n",
       "         N_CA       N_CAROT   ...    HE_BUN  HE_TG  HE_chol  BM8  BM7  BE3_31  \\\n",
       "0  354.696362   2123.850327   ...      10.2   66.0    186.0  2.0  2.0     8.0   \n",
       "1  640.070701    286.469587   ...      13.3   94.0    139.0  3.0  3.0     6.0   \n",
       "2  595.618808   8277.230522   ...       6.7  215.0    175.0  5.0  2.0     8.0   \n",
       "3  451.542912   4011.061803   ...      14.7   49.0    160.0  5.0  4.0     1.0   \n",
       "4  312.266760  10330.283306   ...      13.8   96.0    195.0  5.0  5.0     8.0   \n",
       "5   19.642663     17.056209   ...      26.9  102.0    207.0  2.0  2.0     8.0   \n",
       "6  331.439696   5227.723890   ...      17.9   74.0    130.0  5.0  5.0     8.0   \n",
       "7  239.383662    335.698035   ...      12.1  175.0    266.0  2.0  2.0     8.0   \n",
       "8  409.751881    788.574381   ...      14.3   49.0    202.0  4.0  3.0     4.0   \n",
       "9  671.774181  12941.982092   ...      14.3  162.0    272.0  5.0  4.0     8.0   \n",
       "\n",
       "   L_OUT_FQ  HE_HBsAg  BD1_11  DE1_dg  \n",
       "0       4.0       0.3     8.0     8.0  \n",
       "1       3.0       0.3     3.0     8.0  \n",
       "2       1.0       0.4     5.0     8.0  \n",
       "3       2.0       0.3     2.0     8.0  \n",
       "4       1.0       0.4     4.0     8.0  \n",
       "5       5.0       0.3     8.0     8.0  \n",
       "6       1.0       0.3     8.0     8.0  \n",
       "7       2.0       0.4     4.0     8.0  \n",
       "8       2.0       0.4     4.0     8.0  \n",
       "9       2.0       0.4     4.0     1.0  \n",
       "\n",
       "[10 rows x 74 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_norm = data_pre.transform(data.iloc[:,data.columns!='DE1_dg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_x_norm', data_x_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x = np.loadtxt('data_x.csv',skiprows=1, delimiter=',')\n",
    "data_x_norm = np.load('data_x_norm.npy')\n",
    "data_y = np.loadtxt('data_y.csv', skiprows=1, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = data_y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52681, 73)\n",
      "(52681, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data_x_norm.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_x_norm, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 73))\n",
    "Y = tf.placeholder(tf.float32, shape=(None,1))\n",
    "training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers\n",
    "L = 5\n",
    "# units\n",
    "units=[X.shape[1] ,250,125,62,31,1]   \n",
    "\n",
    "W1 = tf.get_variable('W1',shape=[units[0],units[1]], initializer= tf.contrib.layers.xavier_initializer())\n",
    "B1 = tf.Variable(tf.random_normal([units[1]]))\n",
    "Z1 = tf.matmul(X,W1)+B1\n",
    "# Z1 = tf.layers.batch_normalization(Z1)\n",
    "A1 = tf.nn.relu(Z1)\n",
    "dropout1 = tf.layers.dropout(A1, rate=0.2, training=training)\n",
    "\n",
    "W2 = tf.get_variable('W2',shape=[ units[1],units[2]], initializer= tf.contrib.layers.variance_scaling_initializer())\n",
    "B2 = tf.Variable(tf.random_normal([units[2]]))\n",
    "Z2 = tf.matmul(A1,W2)+B2\n",
    "Z2 = tf.layers.batch_normalization(Z2)\n",
    "A2 = tf.nn.relu(Z2)\n",
    "dropout2 = tf.layers.dropout(A2, rate=0.2, training=training)\n",
    "\n",
    "W3 = tf.get_variable('W3',shape=[ units[2],units[3]], initializer= tf.contrib.layers.variance_scaling_initializer())\n",
    "B3 = tf.Variable(tf.random_normal([units[3]]))\n",
    "Z3 = tf.matmul(A2,W3)+B3\n",
    "Z3 = tf.layers.batch_normalization(Z3)\n",
    "A3 = tf.nn.relu(Z3)\n",
    "dropout3 = tf.layers.dropout(A3, rate=0.2, training=training)\n",
    "\n",
    "W4 = tf.get_variable('W4',shape=[ units[3],units[4]], initializer= tf.contrib.layers.variance_scaling_initializer())\n",
    "B4 = tf.Variable(tf.random_normal([units[4]]))\n",
    "Z4 = tf.matmul(A3,W4)+B4\n",
    "A4 = tf.nn.relu(Z4)\n",
    "dropout4 = tf.layers.dropout(A4, rate=0.2, training=training)\n",
    "\n",
    "W5 = tf.get_variable('W5', shape = [units[4], units[5]], initializer = tf.contrib.layers.variance_scaling_initializer())\n",
    "B5 = tf.Variable(tf.random_normal([units[5]]))\n",
    "Z5 = tf.matmul(A4,W5)+B5\n",
    "\n",
    "logits = tf.nn.sigmoid(Z5)\n",
    "\n",
    "# cost = tf.reduce_mean(tf.matmul(tf.log(tf.transpose(logits)),Y) + \n",
    "#                                  tf.matmul(tf.log(1-tf.transpose(logits)),(1-Y)))\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels= Y, logits=Z5)))\n",
    "# cost = -tf.reduce_mean(tf.reduce_sum((Y * tf.log(logits)) + ((1-Y) * tf.log(1-logits))))\n",
    "# cost = -tf.reduce_mean(Y * tf.log(logits) + (1 - Y) * tf.log(1 - logits),axis=0)\n",
    "# cost  = -tf.reduce_mean(tf.reduce_sum(Y * tf.log(logits),axis=1))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.005).minimize(cost)\n",
    "\n",
    "# predicted = tf.nn.sigmoid(Z5)\n",
    "# correct_pred = tf.equal(tf.round(predicted), Y)\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter : 0, cost : 19.633949279785156\n",
      "iter : 100, cost : 18.661846160888672\n",
      "iter : 200, cost : 18.58959197998047\n",
      "iter : 300, cost : 11.12685489654541\n",
      "iter : 400, cost : 10.4171142578125\n",
      "iter : 500, cost : 10.12913990020752\n",
      "iter : 600, cost : 10.366851806640625\n",
      "iter : 700, cost : 7.059657573699951\n",
      "iter : 800, cost : 7.055397987365723\n",
      "iter : 900, cost : 7.054274082183838\n",
      "iter : 1000, cost : 7.053788185119629\n",
      "iter : 1100, cost : 7.053477764129639\n",
      "iter : 1200, cost : 7.053239822387695\n",
      "iter : 1300, cost : 7.053056716918945\n",
      "iter : 1400, cost : 7.052919387817383\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# mini -> 128 ->500\n",
    "mini = 500\n",
    "n_mini = 1500//mini\n",
    "for i in range(1500):\n",
    "    for j in range(n_mini):\n",
    "        c , _ = sess.run([cost, optimizer], \n",
    "                         feed_dict={X: X_train[j * mini : (j+1) * mini], Y: y_train[j * mini : (j+1) * mini],\n",
    "                                   training:True})\n",
    "    c , _ = sess.run([cost, optimizer], \n",
    "                         feed_dict={X: X_train[n_mini * mini :], Y: y_train[n_mini * mini :],\n",
    "                                   training:True})\n",
    "    \n",
    "    if i%100==0:\n",
    "        print('iter : {}, cost : {}'.format(i,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = sess.run(tf.round(tf.nn.sigmoid(Z5)), feed_dict={X:X_test, training:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138274651229003"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "np.mean(np.equal(yhat_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33915574963609896"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1 score\n",
    "f1_score(y_test,yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a514d9bc50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, yhat_test)\n",
    "sns.heatmap(cm,annot=True,fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:/users/nb-0242/jupyter/PHR_DNN'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model save\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess,'c:/users/nb-0242/jupyter/PHR_DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
